{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e3d3dd0-32a8-4d3c-8087-d117a3892d68",
   "metadata": {},
   "source": [
    "# Explains\n",
    "\n",
    "* To convert ipynb file to python (*.py) and run optimization\n",
    "```\n",
    "jupyter-nbconvert --to script run_OptimizationERA5.ipynb\n",
    "python run_OptimizationERA5.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad6eb52-202b-4b60-bc69-80b24779257d",
   "metadata": {},
   "source": [
    "# Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a960ff0d-c5cc-46ea-a3a7-6bcf6a1fc47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnotebook():\n",
    "   try:\n",
    "      from IPython import get_ipython\n",
    "      if 'IPKernelApp' not in get_ipython().config:  # pragma: no cover\n",
    "         return False\n",
    "   except ImportError:\n",
    "      return False\n",
    "   except AttributeError:\n",
    "      return False\n",
    "   return True\n",
    "if isnotebook():\n",
    "   %matplotlib inline\n",
    "   %load_ext autoreload\n",
    "   %autoreload 2\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas, json\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../install/lib')\n",
    "sys.path.append('../src')\n",
    "import pyseb\n",
    "from pyseb.utils import Dewpoint2SpecificHumidity, VaporPressure, AirDensityFromSpecificHumidity\n",
    "from pyseb.utils.evalMatrix import *\n",
    "\n",
    "import copy\n",
    "from issmmodules import *\n",
    "import scipy\n",
    "import scipy.io\n",
    "import tqdm\n",
    "import datetime # checking elapsed time.\n",
    "\n",
    "# parallel computing\n",
    "import multiprocessing\n",
    "\n",
    "from interpRACMO23p2_ERA5 import *\n",
    "from interpXarrayGridToMesh import *\n",
    "import xarray\n",
    "import shutil\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfaa059-2a60-4928-aadf-06c36def26bc",
   "metadata": {},
   "source": [
    "# Initialize arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc4a54-2cc2-4053-a5a7-585030fe0381",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(prog='Optimization',\n",
    "                            description='Estimate the SEMIC parameters with PSO method')\n",
    "parser.add_argument('-ngen',type=int,\n",
    "                   help='Set number of generation',\n",
    "                   default=2)\n",
    "parser.add_argument('-npop',type=int,\n",
    "                   help='Set number of population',\n",
    "                   default=10)\n",
    "parser.add_argument('-ncpu',default=30,type=int,\n",
    "                   help='Set set number of cpu for parallel computing',)\n",
    "parser.add_argument('-omega',default=0.5, type=float,\n",
    "                   help='Inertia weight (high -> global optial, low -> local optimal)',\n",
    "                   )\n",
    "parser.add_argument('-f',\n",
    "                   help='dummy part for ipython')\n",
    "parser.add_argument('-datadir',type=str,\n",
    "                   default='./data/PSO')\n",
    "parser.add_argument('-debug',type=int,\n",
    "                   default=0)\n",
    "parser.add_argument('-freq',type=str,default='day',\n",
    "                   help='frequnecy of forcing variable. \"day\" or \"mon\" is available.')\n",
    "parser.add_argument('-amp_max',type=float, default=5,\n",
    "                    help='Available maximum temperature amplitude for \"monthly\" experiment\". (default: 5)',\n",
    "                    )\n",
    "parser.add_argument('-tqdm',type=int, default=0,\n",
    "                   help='Show tqdm progress bar. (default: 0)')\n",
    "parser.add_argument('-opt_method',type=int,default=1,\n",
    "                   help='''optimization method for monthly dataset.\n",
    "                   1: use homogeneous melting\n",
    "                   2: use heterogeneous temperature amplitude at each basin.\n",
    "                   3: use some multiplication at each baseh''')\n",
    "args = parser.parse_args()\n",
    "\n",
    "if isnotebook():\n",
    "    args.freq      = 'mon'\n",
    "    args.ngen  = 2\n",
    "    args.npop  = 10\n",
    "    args.nloop = 2\n",
    "    args.opt_method=2\n",
    "    args.debug = 1 # force to change\n",
    "    args.amp_max  = 10.\n",
    "    args.tqdm = True\n",
    "\n",
    "print(f'Information with given argument.')\n",
    "print(f'datadir: {args.datadir}')\n",
    "print(f'npop:    {args.npop}')\n",
    "print(f'ngen:    {args.ngen}')\n",
    "print(f'freq:    {args.freq}')\n",
    "print(f'-- amp_max: {args.amp_max}')\n",
    "print(f'debug:   {args.debug}')\n",
    "print(f'opt_method: {args.opt_method}')\n",
    "print(f'===== system information')\n",
    "print(f'number of cpu: {args.ncpu}')\n",
    "\n",
    "if os.path.isdir(args.datadir):\n",
    "    print('   Remove existing directory')\n",
    "    shutil.rmtree(args.datadir)\n",
    "os.mkdir(args.datadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea363afe-b5ef-46ad-943f-3fa6431aa140",
   "metadata": {},
   "source": [
    "# Load ANT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef12997-86bb-48ab-b4ee-57bda51e42b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Load ANT model')\n",
    "md = loadmodel_netcdf('../data/ANT_Mesh.nc')\n",
    "racmo_melt, racmo_time = interpRACMO23p2_ERA5(md.mesh.lat, md.mesh.long, 'snowmelt',\n",
    "                          'time',[datetime.datetime(1980,1,1), datetime.datetime(2001,1,1)])\n",
    "print(f'Load ANT: extract melting region.')\n",
    "md = md.extract(racmo_melt.mean(axis=1) > 0.)\n",
    "print(f'   number of vertices: {md.mesh.numberofvertices}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d273ead-fbb0-4fc9-b77e-1b74c50a8b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'IMBIE2: interpolate imbie mask')\n",
    "nc = netCDF4.Dataset('../data/IMBIE2/basinNumbers_8km.nc')\n",
    "mask_imbie = interpXarrayGridToMesh('../data/IMBIE2/basinNumbers_8km.nc', md.mesh.x, md.mesh.y,\n",
    "                             xname='x',yname='y',varname='basinNumber',method='nearest')\n",
    "mask_imbie = np.array(mask_imbie.values, dtype=int) # extract only values!\n",
    "if isnotebook():\n",
    "    print(f'IMBIE2: {np.unique(mask_imbie)}')\n",
    "    plotmodel(md,'data',mask_imbie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c85b459-5689-4112-98f5-723b5eaf5c8c",
   "metadata": {},
   "source": [
    "# Load RACMO23p2-ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f80020-a88b-4f7e-94f0-033097032992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m/yr -> water m/sec\n",
    "rho_ice = 917\n",
    "rho_freshwater = 1000;\n",
    "yts = 365*24*3600\n",
    "isunit = rho_ice/rho_freshwater*yts\n",
    "racmo_smb, racmo_time = interpRACMO23p2_ERA5(md.mesh.lat, md.mesh.long, 'snowmelt',\n",
    "                          'time',[datetime.datetime(1980,1,1), datetime.datetime(2001,1,1)])\n",
    "racmo_smb = racmo_smb * isunit\n",
    "\n",
    "racmo_melt, racmo_time = interpRACMO23p2_ERA5(md.mesh.lat, md.mesh.long, 'snowmelt',\n",
    "                          'time',[datetime.datetime(1980,1,1), datetime.datetime(2001,1,1)])\n",
    "racmo_melt = racmo_melt * isunit\n",
    "\n",
    "# surface temperature (unit: K)\n",
    "racmo_tsurf, racmo_time = interpRACMO23p2_ERA5(md.mesh.lat, md.mesh.long, 'tskin',\n",
    "                          'time',[datetime.datetime(1980,1,1), datetime.datetime(2001,1,1)])\n",
    "\n",
    "# net shortwave radiation (unit: K)\n",
    "racmo_swsn, racmo_time = interpRACMO23p2_ERA5(md.mesh.lat, md.mesh.long, 'swsn',\n",
    "                          'time',[datetime.datetime(1980,1,1), datetime.datetime(2001,1,1)],\n",
    "                          'use_cftime',1)\n",
    "\n",
    "print('Generate Xarray')\n",
    "dsracmo = xarray.Dataset(data_vars={'smb':(['nx','time'], racmo_smb),\n",
    "                                   'melt':(['nx','time'], racmo_melt),\n",
    "                                   'swsn':(['nx','time'], racmo_swsn),\n",
    "                                   'tsurf':(['nx','time'], racmo_tsurf)},\n",
    "                        coords={'x':('nx',md.mesh.x),\n",
    "                               'y':('nx',md.mesh.y),\n",
    "                               'time':('time',racmo_time)})\n",
    "del racmo_smb, racmo_melt, racmo_tsurf, racmo_swsn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074708ec-c7ec-40b7-a9fc-1775bebc77fa",
   "metadata": {},
   "source": [
    "# Load ERA5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371ac7ce-9811-407f-9460-bfe98b457c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0: # interpoalte! dataset\n",
    "    data_era5 = {}\n",
    "    for varname in ['d2m','t2m','msr','mtpr','msdwlwrf','msdwswrf','sp','wind2m']:\n",
    "        print(f'Processing... {varname}')\n",
    "        ds = interpCDO(md.mesh.lat, md.mesh.long,\n",
    "                       f'../data/ERA5/day/era5_{varname}_1980,2000.nc', varname=varname)\n",
    "        data_era5[varname] = ds[varname].values\n",
    "    \n",
    "    print('Save dataset in matlab format.')\n",
    "    scipy.io.savemat('../data/Prepare/ANT_InterpERA5.mat',data_era5)\n",
    "else:\n",
    "    if args.freq == 'day':\n",
    "        print('Load saved dataset.')\n",
    "        data_era5 = scipy.io.loadmat('../data/Prepare/ANT_InterpERA5_Day_1980,2000.mat')\n",
    "    elif args.freq == 'mon':\n",
    "        data_era5 = scipy.io.loadmat('../data/Prepare/ANT_InterpERA5_Month_1980,2000.mat')\n",
    "    else:\n",
    "        raise Exception(f'ERROR: Given freq(={args.freq}) is not available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b75226-c293-41e1-b09e-d29975e6c561",
   "metadata": {},
   "source": [
    "# Initialize forcing variables of ERA5 for SEMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba8b4d-7b85-4941-ba11-51a808a6a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_freshwater = 1000 # kg m-3\n",
    "\n",
    "# extract ice shelf region\n",
    "# pos_iceshelf = np.where(md.mask.ocean_levelset < 0)[0]\n",
    "# pos_iceshelf = np.where(np.ones((md.mesh.numberofvertices,)))[0]\n",
    "pos_iceshelf = md.mesh.extractedvertices-1\n",
    "\n",
    "print('ERA5: Set forcing variable for SEMIC.')\n",
    "sf = data_era5['msr'].T/rho_freshwater\n",
    "rf = (data_era5['mtpr'].T - data_era5['msr'].T)/rho_freshwater\n",
    "\n",
    "t2m = data_era5['t2m'].T\n",
    "sp  = data_era5['sp'].T # surface pressure\n",
    "lwd = data_era5['msdwlwrf'].T\n",
    "swd = data_era5['msdwswrf'].T\n",
    "\n",
    "wind = data_era5['wind2m'].T\n",
    "\n",
    "# estimate the air density and specific humidity\n",
    "print('ERA5: Prepare specific humidity and air density')\n",
    "qs = Dewpoint2SpecificHumidity(data_era5['d2m'], data_era5['sp'])\n",
    "rho_air = AirDensityFromSpecificHumidity(data_era5['sp'], data_era5['t2m'], q=qs)\n",
    "qq = qs.T\n",
    "rhoa = rho_air.T\n",
    "\n",
    "print('ERA5: Extract ice shelf values.')\n",
    "force = {}\n",
    "force['sf']  = sf[pos_iceshelf,:]\n",
    "force['rf']  = rf[pos_iceshelf,:]\n",
    "force['t2m'] = t2m[pos_iceshelf,:]\n",
    "force['sp']  = sp[pos_iceshelf,:]\n",
    "force['lwd'] = lwd[pos_iceshelf,:]\n",
    "force['swd'] = swd[pos_iceshelf,:]\n",
    "force['wind']= wind[pos_iceshelf,:]\n",
    "force['qq']  = qq[pos_iceshelf,:]\n",
    "force['rhoa']= rhoa[pos_iceshelf,:]\n",
    "nx    = np.shape(qq)[0]\n",
    "ntime = np.shape(qq)[1]\n",
    "\n",
    "print(f'ERA5: Available maximum size of time: {ntime}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539bb60c-f0bd-4b2f-904a-9e61a2590615",
   "metadata": {},
   "source": [
    "# Prepare PSO optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c806d9b-8907-451c-b934-ed047c8843cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import math\n",
    "\n",
    "from deap import base\n",
    "from deap import creator, tools\n",
    "import random\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fdccdb-e541-4c1b-97f2-472aff25cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization with parameters\n",
    "#              min, max, smin, smax\n",
    "opts = {}\n",
    "if args.freq == 'day':\n",
    "    opts['amp']      = [1, 5]\n",
    "    opts['hcrit']    = [np.log10(0.001), np.log10(1)]\n",
    "    opts['rcrit']    = [0, 1]\n",
    "    opts['mcrit']    = [np.log10(1e-9), np.log10(1e-7)]\n",
    "    opts['alb_smax'] = [0.7, 0.95]\n",
    "    opts['alb_smin'] = [0.2, 0.6]\n",
    "    opts['albi']     = [0.2, 0.6]\n",
    "elif args.freq == 'mon':\n",
    "    if args.opt_method == 1:\n",
    "        opts['amp']      = [1, 5]\n",
    "        opts['hcrit']    = [np.log10(0.001), np.log10(1)]\n",
    "        opts['rcrit']    = [0, 1]\n",
    "        opts['mcrit']    = [np.log10(1e-9), np.log10(1e-7)]\n",
    "        opts['alb_smax'] = [0.7, 0.95]\n",
    "        opts['alb_smin'] = [0.2, 0.6]\n",
    "        opts['albi']     = [0.2, 0.6]\n",
    "    elif args.opt_method == 2:\n",
    "        for nb in range(16):\n",
    "            opts['amp%d'%(nb)] = [1, args.amp_max]\n",
    "        opts['hcrit']    = [np.log10(0.001), np.log10(1)]\n",
    "        opts['rcrit']    = [0, 1]\n",
    "        opts['mcrit']    = [np.log10(1e-9), np.log10(1e-7)]\n",
    "        opts['alb_smax'] = [0.7, 0.95]\n",
    "        opts['alb_smin'] = [0.2, 0.6]\n",
    "        opts['albi']     = [0.2, 0.6]\n",
    "    else:\n",
    "        raise Exception(\"ERROR: Given option is not available.\")\n",
    "else:\n",
    "    raise Exception('ERROR: Not supported yet.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274b1a0-e9b4-465d-b3e4-0c31164b1f0b",
   "metadata": {},
   "source": [
    "# Initialize particle information\n",
    "\n",
    "## SEMIC-day experiment\n",
    "\n",
    "## SEMIC-mon experiment\n",
    "\n",
    "* Amplitude of maximum temperature should be larger than previous one (e.g., 5 K)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e71885d-4aa3-4d9b-9a7b-753f71323d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Particle\", dict, fitness=creator.FitnessMin, speed=list, \n",
    "    smin=None, smax=None, pmin=None, pmax=None, best=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40439ad-f9b5-4891-aca8-225517c36377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(opts_bnd):\n",
    "    _parts = {}\n",
    "    smin   = []\n",
    "    smax   = []\n",
    "    # maximum and minimum position for each particle.\n",
    "    pmax   = []\n",
    "    pmin   = []\n",
    "    for key, value in opts_bnd.items():\n",
    "        _parts[key] = random.uniform(value[0], value[1])\n",
    "        smin.append(-0.2*(value[1] - value[0]))\n",
    "        smax.append( 0.2*(value[1] - value[0]))\n",
    "        pmax.append(value[1])\n",
    "        pmin.append(value[0])\n",
    "    # _parts = [random.uniform(_pmin, _pmax) for _pmin, _pmax in zip(pmin, pmax)]\n",
    "    part = creator.Particle(_parts) \n",
    "    part.speed = [random.uniform(_smin, _smax) for _smin, _smax in zip(smin, smax)]\n",
    "    part.smin = smin\n",
    "    part.smax = smax\n",
    "    part.pmin = pmin\n",
    "    part.pmax = pmax\n",
    "    \n",
    "    return part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2c6e2b-86ba-4d53-8985-b4286649cc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParticle(part, best, phi1=2, phi2=2, omega=args.omega):\n",
    "    '''update particle location\n",
    "    '''\n",
    "    npts = len(part.speed)\n",
    "    loc             = []\n",
    "    loc_local_best  = []\n",
    "    loc_global_best = []\n",
    "    for key in part.keys():\n",
    "        loc.append(part[key])\n",
    "        loc_local_best.append(part.best[key])\n",
    "        loc_global_best.append(best[key])\n",
    "    \n",
    "    u1 = (random.uniform(0, phi1) for _ in range(len(part)))\n",
    "    u2 = (random.uniform(0, phi2) for _ in range(len(part)))\n",
    "    v_u1 = map(operator.mul, u1, map(operator.sub, loc_local_best,  loc))\n",
    "    v_u2 = map(operator.mul, u2, map(operator.sub, loc_global_best, loc))\n",
    "    part.speed = list(map(operator.add, list(map(operator.mul, [omega]*npts, part.speed)),\n",
    "                          map(operator.add, v_u1, v_u2)))\n",
    "\n",
    "    # constrain its maximum and minimum speed.\n",
    "    for i, speed in enumerate(part.speed):\n",
    "        if abs(speed) < part.smin[i]:\n",
    "            part.speed[i] = math.copysign(part.smin[i], speed)\n",
    "        elif abs(speed) > part.smax[i]:\n",
    "            part.speed[i] = math.copysign(part.smax[i], speed)\n",
    "    loc = list(map(operator.add, loc, part.speed))\n",
    "\n",
    "    # constrain its max. and min. position\n",
    "    for idx, key, value in zip(range(len(part)), part.keys(), part.values()):\n",
    "        if part[key] > part.pmax[idx]:\n",
    "            part[key] = part.pmax[idx]\n",
    "        if part[key] < part.pmin[idx]:\n",
    "            part[key] = part.pmin[idx]\n",
    "\n",
    "    # update dict\n",
    "    for idx, key in enumerate(part.keys()):\n",
    "        part[key] = loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840174fb-7051-4005-9dd9-38e55a62fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateSEMIC(part, md, mask_imbie, force, nx=12744, ntime=365, nloop=2):\n",
    "    '''\n",
    "    opt_amp      = [1, 5]\n",
    "    opt_hcrit    = [np.log10(0.001), np.log10(1)]\n",
    "    opt_rcrit    = [0, 1]\n",
    "    opt_mcrit    = [np.log10(1e-9), np.log10(1e-7)]\n",
    "    opt_alb_smax = [0.7, 0.95]\n",
    "    opt_alb_smin = [0.2, 0.6]\n",
    "    opt_albi     = [0.2, 0.6]\n",
    "    '''\n",
    "    # print('Initialize structure')\n",
    "    semic = pyseb.SEMIC()\n",
    "    \n",
    "    semic.Initialize(nx)\n",
    "    ONES = np.ones((nx,),dtype=float)\n",
    "    semic.mask = 2*np.ones((nx,),dtype=int)\n",
    "    semic.verbose = 0\n",
    "    semic.alb_scheme = 3 # use isba albedo scheme\n",
    "    \n",
    "    semic.alb = 0.8*ONES[:]\n",
    "    semic.alb_snow = 0.8*ONES[:]\n",
    "    semic.tsurf = 260.*ONES[:]\n",
    "    semic.hsnow = 5*ONES[:]\n",
    "    semic.hice  = 0*ONES[:]\n",
    "    \n",
    "    # update parameter\n",
    "    semic.Param.ceff = 2e+6\n",
    "    semic.Param.csh  = 2e-3\n",
    "    semic.Param.clh  = 5e-4\n",
    "    if args.freq == 'day':\n",
    "        semic.Param.amp  = part['amp']*ONES[:]\n",
    "    elif args.freq == 'mon':\n",
    "        if args.opt_method == 1:\n",
    "            semic.Param.amp = part['amp']*ONES[:]\n",
    "        elif args.opt_method == 2:\n",
    "            amp = ONES[:]\n",
    "            for nb in range(16):\n",
    "                pos = (mask_imbie == nb)\n",
    "                amp[pos] = part['amp%d'%(nb)]\n",
    "            semic.Param.amp = amp[:]\n",
    "    semic.Param.alb_smax = part['alb_smax']\n",
    "    semic.Param.alb_smin = part['alb_smin']\n",
    "    semic.Param.albi = part['albi']\n",
    "    semic.Param.albl = 0.15\n",
    "    semic.Param.hcrit = 10**part['hcrit']\n",
    "    semic.Param.rcrit = part['rcrit']\n",
    "    semic.Param.mcrit = 10**part['mcrit']\n",
    "    \n",
    "    # initialize results array\n",
    "    # ntime = 365\n",
    "    smb     = np.zeros((nx,ntime))\n",
    "    # smb_snow= np.zeros((nx,ntime))\n",
    "    melt    = np.zeros((nx,ntime))\n",
    "    tsurf   = np.zeros((nx,ntime))\n",
    "    alb     = np.zeros((nx,ntime))\n",
    "    netswd  = np.zeros((nx,ntime))\n",
    "    shf     = np.zeros((nx,ntime))\n",
    "    lhf     = np.zeros((nx,ntime))\n",
    "\n",
    "    for loop in range(nloop):\n",
    "        for i in range(ntime):\n",
    "            semic.sf   = force['sf'][:,i]\n",
    "            semic.rf   = force['rf'][:,i]\n",
    "            semic.swd  = force['swd'][:,i]\n",
    "            semic.lwd  = force['lwd'][:,i]\n",
    "            semic.wind = force['wind'][:,i]\n",
    "            semic.sp   = force['sp'][:,i]\n",
    "            semic.rhoa = force['rhoa'][:,i]\n",
    "            semic.qq   = force['qq'][:,i]\n",
    "            semic.t2m  = force['t2m'][:,i]\n",
    "            semic.RunEnergyAndMassBalance()\n",
    "            # break\n",
    "            if loop == nloop-1:\n",
    "                smb[:,i]   = semic.smb\n",
    "                melt[:,i]  = semic.melt\n",
    "                tsurf[:,i] = semic.tsurf\n",
    "                alb[:,i]   = semic.alb\n",
    "                netswd[:,i]= (1-alb[:,i])*force['swd'][:,i]\n",
    "\n",
    "    # return ds file values\n",
    "    semic_time = pandas.date_range(datetime.datetime(1980,1,1), periods=ntime)\n",
    "    dssemic = xarray.Dataset(data_vars={'smb':(['nx','time'], smb),\n",
    "                                       'melt':(['nx','time'], melt),\n",
    "                                       'swsn':(['nx','time'], netswd),\n",
    "                                       'tsurf':(['nx','time'], tsurf)},\n",
    "                            coords={'x':('nx',md.mesh.x),\n",
    "                                   'y':('nx',md.mesh.y),\n",
    "                                   'time':('time',semic_time)})\n",
    "    dssemic = dssemic.resample(time=\"1MS\").mean(dim='time')\n",
    "\n",
    "    del smb, melt, tsurf, alb, netswd\n",
    "\n",
    "    # print('Evaluate matrix with cRMSE')\n",
    "    matric1 = np.zeros((nx,))\n",
    "    matric2 = np.zeros((nx,))\n",
    "    matric3 = np.zeros((nx,))\n",
    "    matric4 = np.zeros((nx,))\n",
    "    \n",
    "    for i in range(nx):\n",
    "        if args.debug:\n",
    "            matric1[i] = nCRMSE(dsracmo['tsurf'][i,:12].values, dssemic['tsurf'][:12,i].values, omitnan=1)\n",
    "            matric2[i] = nCRMSE(dsracmo['melt'][i,:12].values,  dssemic['melt'][:12,i].values, omitnan=1)\n",
    "            matric3[i] = nCRMSE(dsracmo['swsn'][i,:12].values,  dssemic['swsn'][:12,i].values, omitnan=1)\n",
    "            matric4[i] = nCRMSE(dsracmo['smb'][i,:12].values,  dssemic['smb'][:12,i].values, omitnan=1)\n",
    "        else:\n",
    "            matric1[i] = nCRMSE(dsracmo['tsurf'][i,:].values, dssemic['tsurf'][:,i].values, omitnan=1)\n",
    "            matric2[i] = nCRMSE(dsracmo['melt'][i,:].values,  dssemic['melt'][:,i].values, omitnan=1)\n",
    "            matric3[i] = nCRMSE(dsracmo['swsn'][i,:].values,  dssemic['swsn'][:,i].values, omitnan=1)\n",
    "            matric4[i] = nCRMSE(dsracmo['smb'][i,:].values,  dssemic['smb'][:,i].values, omitnan=1)\n",
    "\n",
    "    matric_fin = np.sqrt(matric1**2 + matric2**2 + matric3**2 + matric4**2)\n",
    "    areas   = GetAreas(md.mesh.elements, md.mesh.x, md.mesh.y)\n",
    "    J = np.sum(areas*np.mean(matric_fin[md.mesh.elements-1],axis=1))\n",
    "\n",
    "    return J\n",
    "\n",
    "def evaluateSEMIC_wrap(part, md, mask_imbie, forc, queue, sema):\n",
    "    if args.debug:\n",
    "        nloop = 2\n",
    "        ntime = 365\n",
    "    else:\n",
    "        nloop = 3\n",
    "        ntime = 7671 # maximum available value\n",
    "    # print(f'evalulate: ntime = {ntime}')\n",
    "    # print(f'evalulate: nloop = {nloop}')\n",
    "    J = evaluateSEMIC(part, md, mask_imbie, forc, ntime=ntime, nloop=nloop)\n",
    "    queue.put(J)\n",
    "    sema.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3d8e1-542f-47f3-aac2-b259b920427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each generation\n",
    "def saveGeneration(fname, pop, best):\n",
    "    data = {}\n",
    "    for idx, part in enumerate(pop):\n",
    "        data[idx] = {'part':part,\n",
    "                  'fitness':part.fitness.values,\n",
    "                  'speed':part.speed,\n",
    "                  'local_best':part.best,\n",
    "                  'local_best_fitness':part.best.fitness.values,\n",
    "                  'global_best':best,\n",
    "                  'global_best_fitness':best.fitness.values}\n",
    "    with open(fname,'w') as fid:\n",
    "        json.dump(data, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98274d26-8293-4232-80da-e582f795a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"particle\", generate, \n",
    "                 opts_bnd=opts)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.particle)\n",
    "toolbox.register(\"update\", updateParticle, phi1=2.0, phi2=2.0)\n",
    "toolbox.register(\"evaluate\", evaluateSEMIC_wrap)\n",
    "\n",
    "if isnotebook():\n",
    "    pop = toolbox.population(n=10) # test\n",
    "    print(pop[0])\n",
    "    print(pop[0].smax)\n",
    "    print(pop[0].smin)\n",
    "    print(pop[0].speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ecae8-9e08-4b67-b936-52d2f8418ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(100)\n",
    "\n",
    "npop = args.npop\n",
    "GEN  = args.ngen\n",
    "datadir = args.datadir #'./data/PSO-dummy/'\n",
    "os.makedirs(datadir,exist_ok=1)\n",
    "\n",
    "best = None\n",
    "output_queue = multiprocessing.Queue()\n",
    "semaphore = multiprocessing.Semaphore(args.ncpu)\n",
    "pop = toolbox.population(n=npop)\n",
    "\n",
    "# initialize log book\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", numpy.mean)\n",
    "stats.register(\"std\", numpy.std)\n",
    "stats.register(\"min\", numpy.min)\n",
    "stats.register(\"max\", numpy.max)\n",
    "\n",
    "logbook = tools.Logbook()\n",
    "logbook.header = [\"gen\", \"evals\"] + stats.fields\n",
    "\n",
    "# initialize pandas dataframe\n",
    "dflog = pandas.DataFrame(columns=['gen','evals','avg','std','min','max'])\n",
    "\n",
    "tstart_glob = datetime.datetime.now()\n",
    "for g in range(GEN):\n",
    "    print('   Generation: %d/%d'%(g+1, GEN))\n",
    "    procs  = []\n",
    "    tstart = datetime.datetime.now()\n",
    "    for part in tqdm.tqdm(pop, bar_format='{l_bar}{bar:20}{r_bar}{bar:-10b}', disable=(not args.tqdm)):\n",
    "        semaphore.acquire()\n",
    "        p = multiprocessing.Process(target=toolbox.evaluate,\n",
    "                                    args=(part, md, mask_imbie, force, output_queue, semaphore),\n",
    "                                   )\n",
    "        procs.append(p)\n",
    "        p.start()\n",
    "\n",
    "    # print('   Join results....')\n",
    "    for p in procs:\n",
    "        p.join()\n",
    "\n",
    "    # print('   get results')\n",
    "    for part in pop:\n",
    "        value = output_queue.get()\n",
    "        part.fitness.values = [value]\n",
    "\n",
    "    # print('   search global and local best.')\n",
    "    for idx, part in enumerate(pop):\n",
    "        if not part.best or part.best.fitness < part.fitness:\n",
    "            part.best = creator.Particle(part)\n",
    "            part.best.fitness.values = part.fitness.values\n",
    "        if not best or best.fitness < part.fitness:\n",
    "            print(f'-- Find global best in {idx}')\n",
    "            best = creator.Particle(part)\n",
    "            best.fitness.values = part.fitness.values\n",
    "\n",
    "    # print('   update particle location.')\n",
    "    # print('-- Previous')\n",
    "    # print(pop[0])\n",
    "    for part in pop:\n",
    "        toolbox.update(part, best)\n",
    "    # print('-- Updated')\n",
    "    # print(pop[0])\n",
    "    \n",
    "    # Gather all the fitnesses in one list and print the stats\n",
    "    logbook.record(gen=g, evals=len(pop), **stats.compile(pop))\n",
    "    print(logbook.stream)\n",
    "\n",
    "    # okay, save each particle dataset\n",
    "    saveGeneration(os.path.join(datadir,'PSO_gen%03d.json'%(g)), pop, best)\n",
    "\n",
    "    dflog.loc[len(dflog)] = logbook[-1]\n",
    "    dflog.to_csv(os.path.join(datadir,'PSO_summary.csv'))\n",
    "\n",
    "    print(f'   Elapsed time: {datetime.datetime.now()-tstart}')\n",
    "\n",
    "print(f'   Total elapsed time: {datetime.datetime.now()-tstart_glob}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
